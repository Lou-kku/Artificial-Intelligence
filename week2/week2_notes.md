# 머신러닝을 하는 순서

1. 데이터 로딩
2. 결측치 확인 및 처리
3. 불필요한 칼럼 제거
4. 레이블 인코딩
5. 타겟 변수와 독립 변수 분리
6. 데이터 분할 (Train/Test)
7. 원하는 모델 학습
8. 모델 평가

---

## 과제하면서 궁금했던 것들 모음

### 레이블 확인을 하는 이유
데이터 불균형이 있으면 모델이 한쪽 클래스로만 예측하려는 경향이 생길 수 있음.

예시: 타이타닉 생존 데이터에서 생존과 사망 데이터 개수가 크게 차이나면, 모델이 대부분 "사망"했다고만 예측할 가능성이 있음.

### 성별을 숫자로 바꾼 이유
머신러닝 모델은 숫자 데이터를 더 잘 처리하므로, 범주형 데이터를 숫자로 변환해야 함.

### 불필요한 칼럼은?
모델 학습에 도움이 되지 않는 칼럼. 예를 들어, `id`나 `Name`처럼 데이터 분석이나 예측에 의미가 없는 칼럼들.

---

## 혼동 행렬이란?

Confusion Matrix(혼동 행렬)는 실제값과 예측값의 관계를 표로 정리한 것.

| 실제 \ 예측 | 생존(1) | 사망(0) |
|------------|---------|---------|
| 생존(1)    | TP      | FN      |
| 사망(0)    | FP      | TN      |

- **TP (True Positive)**: 실제 생존자를 생존으로 맞게 예측
- **TN (True Negative)**: 실제 사망자를 사망으로 맞게 예측
- **FP (False Positive)**: 실제 사망자인데 생존했다고 틀리게 예측
- **FN (False Negative)**: 실제 생존자인데 사망했다고 틀리게 예측

Confusion Matrix는 맞춘 것과 틀린 것을 더 구체적으로 분석하는 데 도움을 줌.
- FN이 많으면 생존자를 사망자로 잘못 예측하는 경향이 있음.
- FP가 많으면 사망자를 생존자로 잘못 예측하는 경향이 있음.

---

## SVM(서포트 벡터 머신)의 커널이란?

SVM은 데이터를 분류할 때 결정 경계(Decision Boundary)를 찾는 알고리즘.

하지만 현실에서는 데이터가 선형적으로 구분되지 않는 경우가 많음. 이때 **커널을 사용하면 데이터를 더 높은 차원으로 변환**해서 선형적으로 분리할 수 있게 도와줌.

즉, **커널은 저차원 데이터를 고차원으로 변환하여 복잡한 데이터도 효과적으로 분류할 수 있도록 하는 방법**임.

### 커널의 종류
1. **선형 커널 (Linear Kernel)**: 데이터가 선형적으로 구분될 때 사용. 계산이 빠르고 해석이 쉬움.
2. **RBF 커널 (Radial Basis Function, 가우시안 커널)**: 비선형 데이터를 다룰 때 가장 많이 사용됨. 데이터 패턴이 복잡할 때 효과적.
3. **다항식 커널 (Polynomial Kernel)**: 다항식 형태로 데이터를 변환하여 복잡한 경계를 만들고 싶을 때 사용.
4. **시그모이드 커널 (Sigmoid Kernel)**: 신경망(Neural Network)에서 사용하는 활성화 함수와 비슷한 방식.

---

## RANDOM_STATE란?

난수의 시드를 고정하는 역할을 함.

매번 실행할 때마다 같은 결과가 나오도록 보장해주는 설정값.

이를 설정하지 않으면, 실행할 때마다 다른 결과가 나올 수 있음.

**Random_State = 42를 많이 쓰는 이유?**
더글라스 애덤스의 소설 *은하수를 여행하는 히치하이커를 위한 안내서*에서 유래했다고 알려져 있음.

---

## KNN이란?

K-Nearest Neighbors (K-최근접 이웃)

KNN은 가장 가까운 K개의 데이터 포인트(이웃)를 찾아 다수를 따르는 방식의 지도 학습 알고리즘.

- **새로운 데이터가 주어지면, 기존 데이터 중 가장 가까운 K개의 점을 찾음.**
- **K개의 점 중 가장 많은 클래스를 선택하여 새로운 데이터를 분류함.** (다수결 원칙)

### K값(K-이웃 수)의 선택
- K가 너무 작으면 → **과적합(Overfitting)** 발생 (노이즈에 민감)
- K가 너무 크면 → **과소적합(Underfitting)** 발생 (일반화 성능 저하)
- 일반적으로 **K=3, 5, 7 같은 홀수 값**을 사용하여 최적의 K를 찾음.

### KNN의 장점과 단점
| 장점 | 단점 |
|------|------|
| 이해하기 쉽고 구현이 간단 | 데이터가 많아지면 계산량이 많아짐 |
| 선형분리되지 않는 데이터도 처리 가능 | K값을 적절히 선택해야 함 |
| 데이터 분포에 대한 가정이 필요 없음 | 거리 계산이 많아지면 속도가 느려짐 |

---

## LR (Logistic Regression)에서 MAX_ITER란?

### **max_iter (최대 반복 횟수)란?**
로지스틱 회귀에서 최적의 가중치를 찾기 위해 **반복 학습하는 횟수**를 의미함.

- 로지스틱 회귀는 **경사 하강법(Gradient Descent)** 을 사용하여 최적의 가중치를 찾음.
- 하지만 반복 횟수가 너무 적으면 최적의 값에 도달하지 못할 수 있음.
- 너무 많이 반복하면 불필요한 연산이 발생할 수 있음.

### **max_iter의 기본값과 조정**
- 기본값: `max_iter=100`
- 데이터가 복잡하거나 수렴이 느릴 경우 → 값을 늘려야 함 (`max_iter=500` 또는 `max_iter=1000`)
- `ConvergenceWarning(수렴하지 않았다는 경고)`이 뜨면 → max_iter를 증가시키는 것이 좋음.

---

## RF (Random Forest)에서 N_ESTIMATORS란?

### **`n_estimators`란?**
랜덤 포레스트(Random Forest)에서 생성할 **결정 트리(Decision Tree)의 개수**를 의미함.

### **랜덤 포레스트에서 `n_estimators`가 중요한 이유**
- 랜덤 포레스트는 **여러 개의 결정 트리를 조합**해서 예측하는 앙상블(ensemble) 모델.
- 트리 개수가 많을수록 안정적인 예측이 가능하지만, 너무 많으면 연산 비용이 커질 수 있음.

### **`n_estimators` 값 조정**
- 기본값: `n_estimators=100`
- 일반적으로 **클수록 성능이 좋아짐** (하지만 너무 크면 연산량 증가)
- 보통 **`n_estimators=100~500`** 정도가 적절함
- 과적합(overfitting)이 걱정된다면, 너무 큰 값은 피하는 게 좋음

---



